# Pydantic Model Library with Outcome-Driven Architecture

**Modular Pydantic library with universal provenance tracking and Graphiti knowledge graph integration.**

---

## ğŸ¯ What This Is

A production-ready Pydantic model library organized by **business outcomes**, not domains. Each "overlay" answers specific business questions with:

- **Minimal schemas** (5-8 entities max per overlay)
- **Universal provenance** (13 node fields + 15 edge fields)
- **Canonical ontology URIs** (DoCO, FaBiO, PROV-O, FIBO, SKOS)
- **Graphiti integration** (type registries + edge validation)
- **Closed-loop validation** (tests verify models answer business questions)

---

## ğŸš€ Quick Start

### Use Existing Models

```python
from pydantic_library.generated.pydantic.overlays.business_outcomes_models import (
    BusinessOutcome,
    OutcomeStatus
)

outcome = BusinessOutcome(
    node_id="outcome_001",
    name="Launch payment feature",
    status=OutcomeStatus.in_progress,
    completion_confidence=0.75
)
```

### Add New Overlay

```bash
# Automated pipeline
python pipeline/add_overlay.py --name "customer_support"

# Or follow 8-step manual workflow
# See: pydantic_library/MIGRATION_GUIDE.md
```

### Run Tests

```bash
cd pydantic_library
python -m pytest tests/ -v
```

**Status**: âœ… 31/31 tests passing

---

## ğŸ“‚ Repository Structure

```
D:\projects\Pydantic Model Generator\
â”‚
â”œâ”€â”€ README.md                          # â† You are here
â”œâ”€â”€ QUICK_START.md                     # 5-minute getting started guide
â”œâ”€â”€ PROJECT_CONTEXT.md                 # Full context for AI continuation
â”‚
â”œâ”€â”€ pydantic_library/                  # Modular Pydantic library
â”‚   â”œâ”€â”€ README.md                      # Library architecture
â”‚   â”œâ”€â”€ MIGRATION_GUIDE.md             # 8-step workflow for adding overlays
â”‚   â”œâ”€â”€ HANDOFF.md                     # Quick recovery for AI
â”‚   â”œâ”€â”€ DECOMPOSITION_REPORT.md        # Final validation metrics
â”‚   â”‚
â”‚   â”œâ”€â”€ schemas/                       # LinkML schemas
â”‚   â”‚   â”œâ”€â”€ core/provenance.yaml       # Universal provenance (13 + 15 slots)
â”‚   â”‚   â”œâ”€â”€ shared/shared_types.yaml   # Cross-outcome types
â”‚   â”‚   â””â”€â”€ overlays/                  # Outcome-specific schemas
â”‚   â”‚       â”œâ”€â”€ business_outcomes_overlay.yaml
â”‚   â”‚       â””â”€â”€ aaoifi_standards_overlay.yaml
â”‚   â”‚
â”‚   â”œâ”€â”€ generated/pydantic/            # Generated Pydantic models
â”‚   â”‚   â”œâ”€â”€ core/provenance.py
â”‚   â”‚   â”œâ”€â”€ shared/shared_types.py
â”‚   â”‚   â””â”€â”€ overlays/
â”‚   â”‚       â”œâ”€â”€ business_outcomes_models.py
â”‚   â”‚       â”œâ”€â”€ business_outcomes_glue.py
â”‚   â”‚       â”œâ”€â”€ aaoifi_standards_models.py
â”‚   â”‚       â””â”€â”€ aaoifi_standards_glue.py
â”‚   â”‚
â”‚   â”œâ”€â”€ specs/                         # OutcomeSpecs (business questions)
â”‚   â”‚   â”œâ”€â”€ business_outcomes.yaml
â”‚   â”‚   â””â”€â”€ aaoifi_standards.yaml
â”‚   â”‚
â”‚   â””â”€â”€ tests/                         # Evidence Query Plans (49 tests)
â”‚       â”œâ”€â”€ test_v1_v2_compatibility.py (18 tests)
â”‚       â””â”€â”€ test_aaoifi_standards.py    (31 tests)
â”‚
â”œâ”€â”€ pipeline/                          # Tools for adding overlays
â”‚   â”œâ”€â”€ README.md                      # Pipeline usage guide
â”‚   â”œâ”€â”€ add_overlay.py                 # Automated overlay creation
â”‚   â”œâ”€â”€ templates/
â”‚   â”‚   â”œâ”€â”€ outcome_spec_template.yaml
â”‚   â”‚   â”œâ”€â”€ overlay_schema_template.yaml
â”‚   â”‚   â””â”€â”€ test_template.py
â”‚   â””â”€â”€ examples/
â”‚
â”œâ”€â”€ docs/                              # Technical documentation
â”‚   â”œâ”€â”€ GRAPHITI_INTEGRATION.md        # How to use with Graphiti
â”‚   â”œâ”€â”€ ONTOLOGY_MAPPING.md            # Canonical URI reference
â”‚   â”œâ”€â”€ AGENT_PIPELINE.md              # AI-assisted overlay generation
â”‚   â””â”€â”€ archive/                       # Historical context
â”‚
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ requirements.txt
â””â”€â”€ Makefile
```

---

## ğŸ—ï¸ Architecture

### Three-Layer Design

```
Core (Universal)
  â”œâ”€ ProvenanceFields (13 slots: node_id, source_uri, extraction_confidence, ...)
  â””â”€ EdgeProvenanceFields (15 slots: rel_id, confidence_score, quote, ...)

Shared (Cross-Outcome)
  â”œâ”€ Deliverable, Milestone, Team
  â””â”€ Reused across multiple overlays

Overlays (Outcome-Specific)
  â”œâ”€ Business Outcomes (4 entities, 6 edges)
  â””â”€ AAOIFI Standards (7 entities, 4 edges)
```

### Key Principles

1. **Outcome-First**: Organize by questions to answer, not domains
2. **Minimalism**: Max 5-8 entities per overlay
3. **Closed-Loop Validation**: Tests verify models answer business questions
4. **Universal Provenance**: Every entity/edge tracks its source
5. **Canonical Ontologies**: Map to standard ontology URIs
6. **Graphiti-Ready**: Type registries for knowledge graph ingestion

---

## ğŸ“Š Current Overlays

### 1. Business Outcomes (4 entities, 6 edges)

**Purpose**: Track deliverables, milestones, task assignments, handoffs

**Entities**:
- BusinessOutcome, BusinessDecision, BusinessTask, BusinessHandoff

**Use Cases**:
- Project planning discussions (Slack, email)
- Task assignment tracking
- Outcome status monitoring
- Decision impact analysis

**Files**:
- Schema: `pydantic_library/schemas/overlays/business_outcomes_overlay.yaml`
- Models: `pydantic_library/generated/pydantic/overlays/business_outcomes_models.py`
- Glue: `pydantic_library/generated/pydantic/overlays/business_outcomes_glue.py`
- Tests: `pydantic_library/tests/test_v1_v2_compatibility.py` (18 tests)

### 2. AAOIFI Standards (7 entities, 4 edges)

**Purpose**: Model Islamic finance standards documents with provenance

**Entities**:
- Document, Section, Paragraph, Concept, ContractType, Rule, Agent

**Use Cases**:
- Standards document ingestion
- Rule provenance tracking
- Compliance requirement extraction
- Concept definition lookup

**Files**:
- Schema: `pydantic_library/schemas/overlays/aaoifi_standards_overlay.yaml`
- Models: `pydantic_library/generated/pydantic/overlays/aaoifi_standards_models.py`
- Glue: `pydantic_library/generated/pydantic/overlays/aaoifi_standards_glue.py`
- Tests: `pydantic_library/tests/test_aaoifi_standards.py` (31 tests)

---

## ğŸ”— Graphiti Integration

### Type Registries

Each overlay provides type registries for Graphiti:

```python
from pydantic_library.generated.pydantic.overlays.business_outcomes_glue import (
    BUSINESS_OUTCOMES_ENTITY_TYPES,
    BUSINESS_OUTCOMES_EDGE_TYPES,
    BUSINESS_OUTCOMES_EDGE_TYPE_MAP,
    validate_edge_type
)

# Validate edge before creation
is_valid = validate_edge_type("BusinessTask", "Actor", "AssignedTo")
```

### Data Flow

```
Business Document
  â†“
Graphiti Episode Ingestion (EpisodeType.message/.text/.json)
  â†“
LLM Entity Extraction
  â†“
Pydantic Model Creation (from extracted entities)
  â†“
Validation with OutcomeSpec Tests
```

**See**: `docs/GRAPHITI_INTEGRATION.md` for complete guide

---

## ğŸ› ï¸ Adding New Overlays

### Option 1: Automated Pipeline (Recommended)

```bash
python pipeline/add_overlay.py --name "customer_support"
```

This creates templates for:
- OutcomeSpec (business questions)
- LinkML schema (entity definitions)
- Pydantic models (auto-generated)
- Glue code (type registries)
- Tests (validation queries)

**See**: `pipeline/README.md` for details

### Option 2: Manual (8-Step Workflow)

1. Create OutcomeSpec (`specs/your_overlay.yaml`)
2. Create LinkML schema (`schemas/overlays/your_overlay.yaml`)
3. Generate Pydantic models (`gen-pydantic`)
4. Create glue code (`generated/pydantic/overlays/your_glue.py`)
5. Write tests (`tests/test_your_overlay.py`)
6. Run tests (`pytest`)
7. Update documentation
8. Commit changes

**See**: `pydantic_library/MIGRATION_GUIDE.md` for complete workflow

---

## ğŸ“š Documentation

### Getting Started
- **[QUICK_START.md](QUICK_START.md)** - 5-minute getting started guide
- **[pydantic_library/README.md](pydantic_library/README.md)** - Library architecture
- **[pydantic_library/HANDOFF.md](pydantic_library/HANDOFF.md)** - Quick recovery for AI

### Adding Overlays
- **[pipeline/README.md](pipeline/README.md)** - Pipeline tools usage
- **[pydantic_library/MIGRATION_GUIDE.md](pydantic_library/MIGRATION_GUIDE.md)** - 8-step workflow

### Integration & Advanced
- **[docs/GRAPHITI_INTEGRATION.md](docs/GRAPHITI_INTEGRATION.md)** - Graphiti usage patterns
- **[docs/ONTOLOGY_MAPPING.md](docs/ONTOLOGY_MAPPING.md)** - Canonical URI reference
- **[docs/AGENT_PIPELINE.md](docs/AGENT_PIPELINE.md)** - AI-assisted generation

### Context Preservation
- **[PROJECT_CONTEXT.md](PROJECT_CONTEXT.md)** - Full project context for AI
- **[docs/archive/](docs/archive/)** - Historical planning documents

---

## ğŸ§ª Testing

### Run All Tests
```bash
cd pydantic_library
python -m pytest tests/ -v
```

### Run Specific Overlay Tests
```bash
python -m pytest tests/test_aaoifi_standards.py -v
```

### Test Structure
- **AAOIFI Standards** (31 tests): OutcomeSpec validation queries

**Current Status**: âœ… 31/31 tests passing

---

## ğŸ”‘ Key Concepts

### OutcomeSpec
Defines business questions your schema must answer:

```yaml
outcome_questions:
  - question: "What tasks are assigned to deliver each outcome?"
    target_entities: [BusinessTask, BusinessOutcome]

validation_queries:
  - name: "test_task_assignment"
    cypher: |
      MATCH (task:BusinessTask)-[r:AssignedTo]->(actor:Actor)
      RETURN task.title, actor.name
```

### Evidence Query Plan (EQP)
Test suite generated from OutcomeSpec to validate models:

```python
def test_task_assignment(self):
    """Validation query: test_task_assignment"""
    task = BusinessTask(node_id="task_001", title="Implement feature")
    actor = Actor(node_id="actor_001", name="John")
    edge = AssignedTo(rel_id="edge_001")

    assert hasattr(task, 'title')
    assert hasattr(actor, 'name')
```

### Universal Provenance
Every entity tracks its source:

```python
outcome = BusinessOutcome(
    node_id="outcome_001",                    # Required, stable ID
    source_uri="slack://channel/planning",    # Source location
    source_document_id="thread_12345",        # Source document
    extraction_confidence=0.9,                # LLM confidence
    extraction_timestamp=datetime.now(),      # When extracted
    # ... + 8 more provenance fields
)
```

### Canonical Ontology URIs
All entities map to standard ontology classes:

```yaml
classes:
  Document:
    class_uri: fabio:SpecificationDocument  # FaBiO ontology
  Section:
    class_uri: doco:Section                 # DoCO ontology
  Rule:
    class_uri: fibo:ContractualElement      # FIBO ontology
```

**Supported Ontologies**:
- **DoCO** (Documents): http://purl.org/spar/doco/
- **FaBiO** (Bibliography): http://purl.org/spar/fabio/
- **PROV-O** (Provenance): http://www.w3.org/ns/prov#
- **FIBO** (Finance): https://spec.edmcouncil.org/fibo/ontology/
- **SKOS** (Concepts): http://www.w3.org/2004/02/skos/core#

---

## ğŸ¯ Design Decisions

### Why Outcome-Driven?
Traditional domain modeling creates bloated schemas trying to model everything. Outcome-driven modeling focuses on answering specific business questions with minimal entities.

### Why 3 Layers?
- **Core**: Universal patterns (provenance) used everywhere
- **Shared**: Common types (Deliverable, Milestone) used across outcomes
- **Overlays**: Outcome-specific entities (minimal, focused)

### Why OutcomeSpecs?
Tests verify models support real business questions. If models can't answer the questions, the schema failed.

### Why Canonical Ontology URIs?
Enables semantic interoperability, data exchange, and integration with existing knowledge graphs.

### Why Graphiti?
Neo4j-backed knowledge graph with LLM-powered entity extraction. Graphiti handles ingestion, we provide type validation.

---

## ğŸš§ Roadmap

### Completed âœ…
- Modular 3-layer architecture
- Universal provenance (13 + 15 fields)
- 2 overlays (Business Outcomes, AAOIFI Standards)
- 31/31 tests passing
- Graphiti type registries
- Pipeline tools for adding overlays

### In Progress ğŸ”¨
- Automated overlay generation from business documents
- AI-assisted OutcomeSpec creation
- Enhanced test generation

### Planned ğŸ”®
- More overlays (customer support, inventory, compliance)
- Graphiti ingestion examples
- Full AI agent pipeline (business doc â†’ Pydantic module)
- Performance benchmarks
- Schema versioning strategy

---

## ğŸ¤ Contributing

### Adding Overlays
1. Use `python pipeline/add_overlay.py --name "your_overlay"`
2. Follow 8-step workflow in `MIGRATION_GUIDE.md`
3. Ensure all tests pass (pytest)
4. Update documentation

### Code Quality
- All entities must include `ProvenanceFields` mixin
- All edges must include `EdgeProvenanceFields` mixin
- Max 5-8 entities per overlay
- Map entities to canonical ontology URIs
- Write OutcomeSpec validation tests

### Testing
- All new overlays must have Evidence Query Plan tests
- All tests must pass before committing
- Test coverage should be >90%

---

## ğŸ“ License

[Your License Here]

---

## ğŸ†˜ Support

- **Quick Start**: `QUICK_START.md`
- **Library Docs**: `pydantic_library/README.md`
- **Pipeline Docs**: `pipeline/README.md`
- **Full Context**: `PROJECT_CONTEXT.md`

---

**Built with**: LinkML â€¢ Pydantic V2 â€¢ Graphiti â€¢ Neo4j

**Status**: âœ… Production Ready (31/31 tests passing)
